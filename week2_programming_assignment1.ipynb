{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('important_words.json.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "2    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "\n",
       "                                              review  rating  sentiment  \n",
       "0  All of my kids have cried non-stop when I trie...       5          1  \n",
       "1  We wanted to get something to keep track of ou...       5          1  \n",
       "2  My daughter had her 1st baby over a year ago. ...       5          1  \n",
       "3  One of baby's first and favorite books, and it...       4          1  \n",
       "4  Very cute interactive book! My son loves this ...       5          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products=pd.read_csv('amazon_baby_subset.csv')\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "products.iloc[0:10,:]\n",
    "products = products.fillna({'review':''})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>My daughter had her 1st baby over a year ago S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>One of babys first and favorite books and it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Very cute interactive book My son loves this b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "2    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  All of my kids have cried non-stop when I trie...       5          1   \n",
       "1  We wanted to get something to keep track of ou...       5          1   \n",
       "2  My daughter had her 1st baby over a year ago. ...       5          1   \n",
       "3  One of baby's first and favorite books, and it...       4          1   \n",
       "4  Very cute interactive book! My son loves this ...       5          1   \n",
       "\n",
       "                                        review_clean  \n",
       "0  All of my kids have cried nonstop when I tried...  \n",
       "1  We wanted to get something to keep track of ou...  \n",
       "2  My daughter had her 1st baby over a year ago S...  \n",
       "3  One of babys first and favorite books and it i...  \n",
       "4  Very cute interactive book My son loves this b...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "def remove_punc(s):\n",
    "    return str(s).translate(table)\n",
    "products['review_clean'] = products['review'].apply(remove_punc)\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loadig json file containing important words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('important_words.json') as imp:\n",
    "    important_words = json.load(imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baby',\n",
       " 'one',\n",
       " 'great',\n",
       " 'love',\n",
       " 'use',\n",
       " 'would',\n",
       " 'like',\n",
       " 'easy',\n",
       " 'little',\n",
       " 'seat',\n",
       " 'old',\n",
       " 'well',\n",
       " 'get',\n",
       " 'also',\n",
       " 'really',\n",
       " 'son',\n",
       " 'time',\n",
       " 'bought',\n",
       " 'product',\n",
       " 'good',\n",
       " 'daughter',\n",
       " 'much',\n",
       " 'loves',\n",
       " 'stroller',\n",
       " 'put',\n",
       " 'months',\n",
       " 'car',\n",
       " 'still',\n",
       " 'back',\n",
       " 'used',\n",
       " 'recommend',\n",
       " 'first',\n",
       " 'even',\n",
       " 'perfect',\n",
       " 'nice',\n",
       " 'bag',\n",
       " 'two',\n",
       " 'using',\n",
       " 'got',\n",
       " 'fit',\n",
       " 'around',\n",
       " 'diaper',\n",
       " 'enough',\n",
       " 'month',\n",
       " 'price',\n",
       " 'go',\n",
       " 'could',\n",
       " 'soft',\n",
       " 'since',\n",
       " 'buy',\n",
       " 'room',\n",
       " 'works',\n",
       " 'made',\n",
       " 'child',\n",
       " 'keep',\n",
       " 'size',\n",
       " 'small',\n",
       " 'need',\n",
       " 'year',\n",
       " 'big',\n",
       " 'make',\n",
       " 'take',\n",
       " 'easily',\n",
       " 'think',\n",
       " 'crib',\n",
       " 'clean',\n",
       " 'way',\n",
       " 'quality',\n",
       " 'thing',\n",
       " 'better',\n",
       " 'without',\n",
       " 'set',\n",
       " 'new',\n",
       " 'every',\n",
       " 'cute',\n",
       " 'best',\n",
       " 'bottles',\n",
       " 'work',\n",
       " 'purchased',\n",
       " 'right',\n",
       " 'lot',\n",
       " 'side',\n",
       " 'happy',\n",
       " 'comfortable',\n",
       " 'toy',\n",
       " 'able',\n",
       " 'kids',\n",
       " 'bit',\n",
       " 'night',\n",
       " 'long',\n",
       " 'fits',\n",
       " 'see',\n",
       " 'us',\n",
       " 'another',\n",
       " 'play',\n",
       " 'day',\n",
       " 'money',\n",
       " 'monitor',\n",
       " 'tried',\n",
       " 'thought',\n",
       " 'never',\n",
       " 'item',\n",
       " 'hard',\n",
       " 'plastic',\n",
       " 'however',\n",
       " 'disappointed',\n",
       " 'reviews',\n",
       " 'something',\n",
       " 'going',\n",
       " 'pump',\n",
       " 'bottle',\n",
       " 'cup',\n",
       " 'waste',\n",
       " 'return',\n",
       " 'amazon',\n",
       " 'different',\n",
       " 'top',\n",
       " 'want',\n",
       " 'problem',\n",
       " 'know',\n",
       " 'water',\n",
       " 'try',\n",
       " 'received',\n",
       " 'sure',\n",
       " 'times',\n",
       " 'chair',\n",
       " 'find',\n",
       " 'hold',\n",
       " 'gate',\n",
       " 'open',\n",
       " 'bottom',\n",
       " 'away',\n",
       " 'actually',\n",
       " 'cheap',\n",
       " 'worked',\n",
       " 'getting',\n",
       " 'ordered',\n",
       " 'came',\n",
       " 'milk',\n",
       " 'bad',\n",
       " 'part',\n",
       " 'worth',\n",
       " 'found',\n",
       " 'cover',\n",
       " 'many',\n",
       " 'design',\n",
       " 'looking',\n",
       " 'weeks',\n",
       " 'say',\n",
       " 'wanted',\n",
       " 'look',\n",
       " 'place',\n",
       " 'purchase',\n",
       " 'looks',\n",
       " 'second',\n",
       " 'piece',\n",
       " 'box',\n",
       " 'pretty',\n",
       " 'trying',\n",
       " 'difficult',\n",
       " 'together',\n",
       " 'though',\n",
       " 'give',\n",
       " 'started',\n",
       " 'anything',\n",
       " 'last',\n",
       " 'company',\n",
       " 'come',\n",
       " 'returned',\n",
       " 'maybe',\n",
       " 'took',\n",
       " 'broke',\n",
       " 'makes',\n",
       " 'stay',\n",
       " 'instead',\n",
       " 'idea',\n",
       " 'head',\n",
       " 'said',\n",
       " 'less',\n",
       " 'went',\n",
       " 'working',\n",
       " 'high',\n",
       " 'unit',\n",
       " 'seems',\n",
       " 'picture',\n",
       " 'completely',\n",
       " 'wish',\n",
       " 'buying',\n",
       " 'babies',\n",
       " 'won',\n",
       " 'tub',\n",
       " 'almost',\n",
       " 'either']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word_count of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in important_words:\n",
    "    products[word] = products['review_clean'].apply(lambda s : s.split().count(word))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**. How many reviews contain the word perfect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2955"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[products['perfect']>0].shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forming a feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(dataframe, features, label):\n",
    "    dataframe['constant'] = 1\n",
    "    features = ['constant'] + features\n",
    "    features_frame = dataframe[features]\n",
    "    feature_matrix = np.array(features_frame)\n",
    "    label_sarray = dataframe[label]\n",
    "    label_array = np.array(label_sarray)\n",
    "    return(feature_matrix, label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix=get_numpy_data(products,important_words,'sentiment')[0]\n",
    "label_array=get_numpy_data(products,important_words,'sentiment')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, ..., -1, -1, -1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: How many features are there in the feature_matrix?\n",
    "*194*\n",
    "\n",
    "\n",
    "**Quiz Question**: Assuming that the intercept is present, how does the number of features in feature_matrix relate to the number of features in the logistic regression model?\n",
    "\n",
    "\n",
    "*-1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def predict_probablity(feature_matrix,coeff):\n",
    "    p=np.dot(feature_matrix,coeff)\n",
    "    p=1/(1+np.exp(-p))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):     \n",
    "    derivative =np.dot(errors,feature)\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_likelihood(feature_matrix, sentiment, coefficients):\n",
    "    indicator = (sentiment==+1)\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    lp = np.sum((indicator-1)*scores - np.log(1. + np.exp(-scores)))\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def logistic_regression(feature_matrix, sentiment, initial_coefficients, step_size, max_iter):\n",
    "    coefficients = np.array(initial_coefficients) # make sure it's a numpy array\n",
    "    for itr in range(0,max_iter):\n",
    "        # Predict P(y_i = +1|x_1,w) using your predict_probability() function\n",
    "        # YOUR CODE HERE\n",
    "        predictions = predict_probablity(feature_matrix,coefficients)\n",
    "\n",
    "        # Compute indicator value for (y_i = +1)\n",
    "        indicator = (sentiment==+1)\n",
    "\n",
    "        # Compute the errors as indicator - predictions\n",
    "        errors = indicator - predictions\n",
    "        ft=np.transpose(feature_matrix)\n",
    "        derivatives=np.dot(ft,errors)\n",
    "        coefficients=np.array(coefficients)+step_size*np.array(derivatives)\n",
    "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
    "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            lp = compute_log_likelihood(feature_matrix, sentiment, coefficients)\n",
    "            print ('iteration %*d: log likelihood of observed labels = %.8f' % \\\n",
    "                (int(np.ceil(np.log10(max_iter))), itr, lp))\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -36780.91768478\n",
      "iteration   1: log likelihood of observed labels = -36775.13434712\n",
      "iteration   2: log likelihood of observed labels = -36769.35713564\n",
      "iteration   3: log likelihood of observed labels = -36763.58603240\n",
      "iteration   4: log likelihood of observed labels = -36757.82101962\n",
      "iteration   5: log likelihood of observed labels = -36752.06207964\n",
      "iteration   6: log likelihood of observed labels = -36746.30919497\n",
      "iteration   7: log likelihood of observed labels = -36740.56234821\n",
      "iteration   8: log likelihood of observed labels = -36734.82152213\n",
      "iteration   9: log likelihood of observed labels = -36729.08669961\n",
      "iteration  10: log likelihood of observed labels = -36723.35786366\n",
      "iteration  11: log likelihood of observed labels = -36717.63499744\n",
      "iteration  12: log likelihood of observed labels = -36711.91808422\n",
      "iteration  13: log likelihood of observed labels = -36706.20710739\n",
      "iteration  14: log likelihood of observed labels = -36700.50205049\n",
      "iteration  15: log likelihood of observed labels = -36694.80289716\n",
      "iteration  20: log likelihood of observed labels = -36666.39512033\n",
      "iteration  30: log likelihood of observed labels = -36610.01327118\n",
      "iteration  40: log likelihood of observed labels = -36554.19728365\n",
      "iteration  50: log likelihood of observed labels = -36498.93316099\n",
      "iteration  60: log likelihood of observed labels = -36444.20783914\n",
      "iteration  70: log likelihood of observed labels = -36390.00909449\n",
      "iteration  80: log likelihood of observed labels = -36336.32546144\n",
      "iteration  90: log likelihood of observed labels = -36283.14615871\n",
      "iteration 100: log likelihood of observed labels = -36230.46102347\n",
      "iteration 200: log likelihood of observed labels = -35728.89418769\n",
      "iteration 300: log likelihood of observed labels = -35268.51212683\n"
     ]
    }
   ],
   "source": [
    "initial_wt=np.array([0]*194)\n",
    "initial_wt.reshape(194,1)\n",
    "coeff=logistic_regression(feature_matrix,label_array,initial_wt,1e-7,301)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz question**: As each iteration of gradient ascent passes, does the log likelihood increase or decrease?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.16220157e-03  1.55656966e-02 -8.50204675e-03  6.65460842e-02\n",
      "  6.58907629e-02  5.01743882e-03 -5.38601484e-02 -3.50488413e-03\n",
      "  6.47945868e-02  4.54356263e-02  3.98353364e-03  2.00775410e-02\n",
      "  3.01350011e-02 -2.87115530e-02  1.52161964e-02  2.72592062e-04\n",
      "  1.19448177e-02 -1.82461935e-02 -1.21706420e-02 -4.15110334e-02\n",
      "  2.76820391e-03  1.77031999e-02 -4.39700067e-03  4.49764014e-02\n",
      "  9.90916464e-03  8.99239081e-04 -1.36219516e-03  1.26859357e-02\n",
      "  8.26466695e-03 -2.77426972e-02  6.10128809e-04  1.54084501e-02\n",
      " -1.32134753e-02 -3.00512492e-02  2.97399371e-02  1.84087080e-02\n",
      "  2.86178752e-03 -1.05768015e-02 -6.57350362e-04 -1.01476555e-02\n",
      " -4.79579528e-03  7.50891810e-03  4.27938289e-03  3.06785501e-03\n",
      " -2.20317661e-03  9.57273354e-03  9.91666827e-05 -1.98462567e-02\n",
      "  1.75702722e-02  1.55478612e-03 -1.77375440e-02  9.78324102e-03\n",
      "  1.17031606e-02 -7.35345937e-03 -6.08714030e-03  6.43766808e-03\n",
      "  1.07159665e-02 -3.05345476e-03  7.17190727e-03  5.73320003e-03\n",
      "  4.60661876e-03 -5.20588421e-03  6.71012331e-03  9.03281814e-03\n",
      "  1.74563147e-03  6.00279979e-03  1.20181744e-02 -1.83594607e-02\n",
      " -6.91010811e-03 -1.38687273e-02 -1.50406590e-02  5.92353611e-03\n",
      "  5.67478991e-03 -5.28786220e-03  3.08147864e-03  5.53751236e-03\n",
      "  1.49917916e-02 -3.35666000e-04 -3.30695153e-02 -4.78990943e-03\n",
      " -6.41368859e-03  7.99938935e-03 -8.61390444e-04  1.68052959e-02\n",
      "  1.32539901e-02  1.72307051e-03  2.98030675e-03  8.58284300e-03\n",
      "  1.17082481e-02  2.80825907e-03  2.18724016e-03  1.68824711e-02\n",
      " -4.65973741e-03  1.51368285e-03 -1.09509122e-02  9.17842898e-03\n",
      " -1.88572281e-04 -3.89820373e-02 -2.44821005e-02 -1.87023714e-02\n",
      " -2.13943485e-02 -1.29690465e-02 -1.71378670e-02 -1.37566767e-02\n",
      " -1.49770449e-02 -5.10287978e-03 -2.89789761e-02 -1.48663194e-02\n",
      " -1.28088380e-02 -1.07709355e-02 -6.95286915e-03 -5.04082164e-03\n",
      " -9.25914404e-03 -2.40427481e-02 -2.65927785e-02 -1.97320937e-03\n",
      " -5.04127508e-03 -7.00791912e-03 -3.48088523e-03 -6.40958916e-03\n",
      " -4.07497010e-03 -6.30054296e-03 -1.09187932e-02 -1.26051900e-02\n",
      " -1.66895314e-03 -7.76418781e-03 -5.15960485e-04 -1.94199551e-03\n",
      " -1.24761586e-03 -5.01291731e-03 -9.12049191e-03 -7.22098801e-03\n",
      " -8.31782981e-03 -5.60573348e-03 -1.47098335e-02 -9.31520819e-03\n",
      " -2.22034402e-03 -7.07573098e-03 -5.10115608e-03 -8.93572862e-03\n",
      " -1.27545713e-02 -7.04171991e-03 -9.76219676e-04  4.12091713e-04\n",
      "  8.29251160e-04  2.64661064e-03 -7.73228782e-03  1.53471164e-03\n",
      " -7.37263060e-03 -3.73694386e-03 -3.81416409e-03 -1.64575145e-03\n",
      " -3.31887732e-03  1.22257832e-03  1.36699286e-05 -3.01866601e-03\n",
      " -1.02826343e-02 -1.06691327e-02  2.23639046e-03 -9.87424798e-03\n",
      " -1.02192048e-02 -3.41330929e-03  3.34489960e-03 -3.50984516e-03\n",
      " -6.26283150e-03 -7.22419943e-03 -5.47016154e-03 -1.25063947e-02\n",
      " -2.47805699e-03 -1.60017985e-02 -6.40098934e-03 -4.26644386e-03\n",
      " -1.55376990e-02  2.31349237e-03 -9.06653337e-03 -6.30012672e-03\n",
      " -1.21010303e-02 -3.02578875e-03 -6.76289718e-03 -5.65498722e-03\n",
      " -6.87050239e-03 -1.18950595e-02 -1.86489236e-04 -1.15230476e-02\n",
      "  2.81533219e-03 -8.10150295e-03 -1.00062131e-02  4.02037651e-03\n",
      " -5.44300346e-03  2.85818985e-03  1.19885003e-04 -6.47587687e-03\n",
      " -1.14493516e-03 -7.09205934e-03]\n"
     ]
    }
   ],
   "source": [
    "print (coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53072\n",
      "25126\n"
     ]
    }
   ],
   "source": [
    "scores=np.dot(feature_matrix,coeff)\n",
    "scores.reshape(scores.shape[0],1)\n",
    "c=0\n",
    "for i in scores:\n",
    "    if i>0:\n",
    "        c=c+1\n",
    "print (c)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz question**: How many reviews were predicted to have positive sentiment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7518653904130238\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "senti=np.array(products['sentiment'])\n",
    "l=0\n",
    "for i in range(0,len(scores)):\n",
    "#     print (products[products.iloc[[i],[3]]])\n",
    "    if scores[i]>0 and senti[i]==1:\n",
    "        correct=correct+1\n",
    "    if scores[i]<=0 and senti[i]==-1:\n",
    "        l=l+1;\n",
    "        correct=correct+1\n",
    "accuracy=correct/len(scores)\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=[]\n",
    "for i in range(1,194):\n",
    "    p.append([coeff[i],important_words[i-1]])\n",
    "p.sort()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz question**: Which word is not present in the top 10 \"most negative\" words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05386014844520313, 'would']\n",
      "[-0.04151103339210889, 'product']\n",
      "[-0.038982037286487116, 'money']\n",
      "[-0.03306951529475273, 'work']\n",
      "[-0.030051249236035808, 'even']\n",
      "[-0.028978976142317068, 'disappointed']\n",
      "[-0.028711552980192585, 'get']\n",
      "[-0.027742697230661327, 'back']\n",
      "[-0.026592778462247283, 'return']\n",
      "[-0.024482100545891717, 'monitor']\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    print(p[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz question**: Which word is not present in the top 10 \"most positive\" words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06654608417045771, 'great']\n",
      "[0.06589076292212324, 'love']\n",
      "[0.0647945868025784, 'easy']\n",
      "[0.04543562630842137, 'little']\n",
      "[0.04497640139490604, 'loves']\n",
      "[0.030135001092107077, 'well']\n",
      "[0.02973993710496846, 'perfect']\n",
      "[0.020077541034775385, 'old']\n",
      "[0.01840870799526899, 'nice']\n",
      "[0.017703199905701697, 'daughter']\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    print(p[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
